{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('gutenberg')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "KingJames = gutenberg.raw(\"bible-kjv.txt\")\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "#I still have trouble with the other tokenizer. I think I'll probably stick with this tokenizer for the year.\n",
    "\n",
    "\n",
    "tokens = tokenizer.tokenize(KingJames)\n",
    "\n",
    "tok_lower= [token.lower() for token in tokens]\n",
    "\n",
    "# Filter out punctuation and stopwords we dont want them influencing the counts later on\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filt_tok = [word for word in tok_lower if word.isalpha() and word not in stop_words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigram Finder This basically does a computation P(x,y)/(P(X)*P(y))\n",
    "bigram_finder = BigramCollocationFinder.from_words(filt_tok)\n",
    "\n",
    "# frequency filter wont consider any with less than 3\n",
    "bigram_finder.apply_freq_filter(3)\n",
    "\n",
    "# Raw Frequency Score This one is biagrams that occur most frequently\n",
    "raw_freq_bigrams = bigram_finder.nbest(BigramAssocMeasures.raw_freq, 20)  \n",
    "\n",
    "# PMI Score This one uses the formula from earlier and goes from highest probaility of occuring together\n",
    "# vs just the highest frequency biagram\n",
    "\n",
    "pmi_bigrams = bigram_finder.nbest(BigramAssocMeasures.pmi, 20) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Bigrams raw frequency:\n",
      "('said', 'unto')\n",
      "('thou', 'shalt')\n",
      "('lord', 'god')\n",
      "('ye', 'shall')\n",
      "('thou', 'hast')\n",
      "('saith', 'lord')\n",
      "('children', 'israel')\n",
      "('unto', 'lord')\n",
      "('came', 'pass')\n",
      "('thus', 'saith')\n",
      "('shall', 'come')\n",
      "('unto', 'thee')\n",
      "('say', 'unto')\n",
      "('lord', 'thy')\n",
      "('thy', 'god')\n",
      "('lord', 'hath')\n",
      "('thou', 'art')\n",
      "('lord', 'shall')\n",
      "('every', 'one')\n",
      "('thee', 'thou')\n",
      "\n",
      "Top 20 bigrams by PMI:\n",
      "('halah', 'habor')\n",
      "('hena', 'ivah')\n",
      "('ikkesh', 'tekoite')\n",
      "('alpha', 'omega')\n",
      "('chancellor', 'shimshai')\n",
      "('zophar', 'naamathite')\n",
      "('bildad', 'shuhite')\n",
      "('blasting', 'mildew')\n",
      "('geshurites', 'maachathites')\n",
      "('sepharvaim', 'hena')\n",
      "('abishag', 'shunammite')\n",
      "('chastised', 'whips')\n",
      "('hammedatha', 'agagite')\n",
      "('nepheg', 'japhia')\n",
      "('sardius', 'topaz')\n",
      "('ahinoam', 'jezreelitess')\n",
      "('cornet', 'flute')\n",
      "('doeg', 'edomite')\n",
      "('grain', 'mustard')\n",
      "('alabaster', 'box')\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 20 Bigrams raw frequency:\")\n",
    "for bigram in raw_freq_bigrams:\n",
    "    print(bigram)\n",
    "\n",
    "print(\"\\nTop 20 bigrams by PMI:\")\n",
    "for bigram in pmi_bigrams:\n",
    "    print(bigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first part, the raw frequencies make sense. For example, phrases like \"Children of Israel\" occur frequently in the Bible, but \"Children\" does not always occur with \"Israel.\" You might also see \"Children of Abraham\" or \"Children of ...\" in other contexts. However, PMI highlights the strength of association between specific words, giving us higher probabilities for words that are strongly connected, such as \"blasting\" (crops) and \"mildew\" (crops). These words often occur together in the context of a specific punishment, and they rarely appear alone or in unrelated contexts.\n",
    "\n",
    "PMI provides insight into the likelihood of certain tokens (words) appearing together. This concept forms the foundation of generative language models (LLMs), which generate text based on the probabilities of word combinations. The model predicts the next token by evaluating the likelihood of it appearing alongside the previous tokens."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
