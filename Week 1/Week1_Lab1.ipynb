{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/codespace/.python/current/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /home/codespace/.python/current/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/codespace/.python/current/lib/python3.12/site-packages (from nltk) (2024.7.24)\n",
      "Requirement already satisfied: tqdm in /home/codespace/.python/current/lib/python3.12/site-packages (from nltk) (4.66.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/codespace/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "from nltk.corpus import brown\n",
    "brown.words()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "brown.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 1 + 2\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentstr = 'I like NLP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like NLP\n"
     ]
    }
   ],
   "source": [
    "print ( sentstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentlist = ['I', 'like', 'NLP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentstr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentlist[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'like'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentlist[1]\n",
    "#sentlist[5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'like']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentlist[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the text with nltk.corpus.gutenberg.raw()\n",
    "#Get the tokens with nltk.word_tokenize()\n",
    "#Get the words by using w.lower() to lowercase the tokens\n",
    "#Make the frequency distribution with FreqDist\n",
    "#Get the 30 top frequency words with most_common(30) and print the word, frequency pairs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "nltk.corpus.gutenberg.fileids()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The King James Bible]\n",
      "\n",
      "The Old Testament of the King James Bible\n",
      "\n",
      "The First Book of Moses:  Called Genesis\n",
      "\n",
      "\n",
      "1:1 In the beginning God created the heaven and the earth.\n",
      "\n",
      "1:2 And the earth was without form, and void; and darkness was upon\n",
      "the face of the deep. And the Spirit of God moved upon the face of the\n",
      "waters.\n",
      "\n",
      "1:3 And God said, Let there be light: and there was light.\n",
      "\n",
      "1:4 And God saw the light, that it was good: and God divided the light\n",
      "from the darkness.\n",
      "\n",
      "1:5 And God called the light Da\n"
     ]
    }
   ],
   "source": [
    "\n",
    "KingJames=nltk.corpus.gutenberg.raw(\"bible-kjv.txt\")\n",
    "print(KingJames[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punkt tokenizer found.\n"
     ]
    }
   ],
   "source": [
    "from nltk.data import find\n",
    "\n",
    "try:\n",
    "    find('tokenizers/punkt')\n",
    "    print(\"Punkt tokenizer found.\")\n",
    "except LookupError:\n",
    "    print(\"Punkt tokenizer not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')\n",
    "#nltk.download('gutenberg')\n",
    "\n",
    "#import nltk\n",
    "#from nltk.tokenize import word_tokenize\n",
    "#from nltk.corpus import gutenberg\n",
    "\n",
    "\n",
    "# Load the text\n",
    "#KingJames = gutenberg.raw(\"bible-kjv.txt\")\n",
    "#print(KingJames)\n",
    "# Tokenize the text\n",
    "#tokens = nltk.word_tokenize(KingJames)  \n",
    "#print(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tokens: ['[', 'The', 'King', 'James', 'Bible', ']', 'The', 'Old', 'Testament', 'of', 'the', 'King', 'James', 'Bible', 'The', 'First', 'Book', 'of', 'Moses', ':', 'Called', 'Genesis', '1:1', 'In', 'the', 'beginning', 'God', 'created', 'the', 'heaven', 'and', 'the', 'earth.', '1:2', 'And', 'the', 'earth', 'was', 'without', 'form', ',', 'and', 'void', ';', 'and', 'darkness', 'was', 'upon', 'the', 'face', 'of', 'the', 'deep.', 'And', 'the', 'Spirit', 'of', 'God', 'moved', 'upon', 'the', 'face', 'of', 'the', 'waters.', '1:3', 'And', 'God', 'said', ',', 'Let', 'there', 'be', 'light', ':', 'and', 'there', 'was', 'light.', '1:4', 'And', 'God', 'saw', 'the', 'light', ',', 'that', 'it', 'was', 'good', ':', 'and', 'God', 'divided', 'the', 'light', 'from', 'the', 'darkness.', '1:5', 'And', 'God', 'called', 'the', 'light', 'Da']\n",
      "Lowercase Tokens: ['[', 'the', 'king', 'james', 'bible', ']', 'the', 'old', 'testament', 'of', 'the', 'king', 'james', 'bible', 'the', 'first', 'book', 'of', 'moses', ':', 'called', 'genesis', '1:1', 'in', 'the', 'beginning', 'god', 'created', 'the', 'heaven', 'and', 'the', 'earth.', '1:2', 'and', 'the', 'earth', 'was', 'without', 'form', ',', 'and', 'void', ';', 'and', 'darkness', 'was', 'upon', 'the', 'face', 'of', 'the', 'deep.', 'and', 'the', 'spirit', 'of', 'god', 'moved', 'upon', 'the', 'face', 'of', 'the', 'waters.', '1:3', 'and', 'god', 'said', ',', 'let', 'there', 'be', 'light', ':', 'and', 'there', 'was', 'light.', '1:4', 'and', 'god', 'saw', 'the', 'light', ',', 'that', 'it', 'was', 'good', ':', 'and', 'god', 'divided', 'the', 'light', 'from', 'the', 'darkness.', '1:5', 'and', 'god', 'called', 'the', 'light', 'da']\n",
      "Uppercase G: ['[', 'the', 'king', 'james', 'bible', ']', 'the', 'old', 'testament', 'of', 'the', 'king', 'james', 'bible', 'the', 'first', 'book', 'of', 'moses', ':', 'called', 'genesis', '1:1', 'in', 'the', 'beginning', 'God', 'created', 'the', 'heaven', 'and', 'the', 'earth.', '1:2', 'and', 'the', 'earth', 'was', 'without', 'form', ',', 'and', 'void', ';', 'and', 'darkness', 'was', 'upon', 'the', 'face', 'of', 'the', 'deep.', 'and', 'the', 'spirit', 'of', 'God', 'moved', 'upon', 'the', 'face', 'of', 'the', 'waters.', '1:3', 'and', 'God', 'said', ',', 'let', 'there', 'be', 'light', ':', 'and', 'there', 'was', 'light.', '1:4', 'and', 'God', 'saw', 'the', 'light', ',', 'that', 'it', 'was', 'good', ':', 'and', 'God', 'divided', 'the', 'light', 'from', 'the', 'darkness.', '1:5', 'and', 'God', 'called', 'the', 'light', 'da']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "KingJames = gutenberg.raw(\"bible-kjv.txt\")\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "tokens = tokenizer.tokenize(KingJames[:500])\n",
    "\n",
    "\n",
    "tokens_lower = [token.lower() for token in tokens]\n",
    "tokens_modified = [token.lower() if not token.startswith('God') else token for token in tokens]\n",
    "#Here I asked Chat GPT of I could modify the lowercase prompt for use cases that may involved Proper Nouns.\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(\"Original Tokens:\", tokens)\n",
    "print(\"Lowercase Tokens:\", tokens_lower)\n",
    "print(\"Uppercase G:\",tokens_modified)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 17, 'and': 10, 'god': 6, 'of': 5, 'was': 4, 'light': 4, ':': 3, ',': 3, 'king': 2, 'james': 2, ...})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "KJFreq=FreqDist(tokens_lower)\n",
    "KJFreq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 17, 'and': 10, 'God': 6, 'of': 5, 'was': 4, 'light': 4, ':': 3, ',': 3, 'king': 2, 'james': 2, ...})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "KJFreq=FreqDist(tokens_modified)\n",
    "KJFreq\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Word  Frequency\n",
      "0         the         17\n",
      "1         and         10\n",
      "2         God          6\n",
      "3          of          5\n",
      "4         was          4\n",
      "5       light          4\n",
      "6           :          3\n",
      "7           ,          3\n",
      "8        king          2\n",
      "9       james          2\n",
      "10      bible          2\n",
      "11     called          2\n",
      "12       upon          2\n",
      "13       face          2\n",
      "14      there          2\n",
      "15          [          1\n",
      "16          ]          1\n",
      "17        old          1\n",
      "18  testament          1\n",
      "19      first          1\n",
      "20       book          1\n",
      "21      moses          1\n",
      "22    genesis          1\n",
      "23        1:1          1\n",
      "24         in          1\n",
      "25  beginning          1\n",
      "26    created          1\n",
      "27     heaven          1\n",
      "28     earth.          1\n",
      "29        1:2          1\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "import pandas as pd\n",
    "\n",
    "# Get the top 10 most common words \n",
    "top_words = KJFreq.most_common(30)\n",
    "\n",
    "# Convert the list into a DataFrame\n",
    "df = pd.DataFrame(top_words, columns=['Word', 'Frequency'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "The most frequent words include common articles, conjunctions, and religious terms such as God.\n",
    "Punctuation marks such as : and , were also counted, which indicates that more preprocessing might be necessary to remove punctuation.\n",
    "Proper nouns like \"King\" and \"James\" appear in the top 10 which makes sence beacause of the passage.\n",
    "\n",
    "Lessons Learned:\n",
    "Preprocessing: It is crucial to clean the text thoroughly, such as removing punctuation and irrelevant tokens, to get a more meaningful frequency analysis of the words.\n",
    "\n",
    "Frequent Words: In most texts, articles and conjunctions (\"the,\" \"and\") dominate the frequency count. To focus on content, these common words can be filtered out as stop words.\n",
    "\n",
    "Context Insights: Word frequency analysis in a religious text reveals key thematic elements like God and light."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
